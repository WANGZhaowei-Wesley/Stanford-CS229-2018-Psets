\begin{answer}
For the MLE $\arg \max\limits_\theta \sum\limits_{i=1}^m \log P_\theta(x^{(i)})$, we can merge diffierent $x^{(i)}$s, if they are equal to each other. So, the merged formula is $\arg \max\limits_\theta \sum\limits_x \hat{P}(x) \log P_\theta(x)$\\
The expanded the KL divergence formula is $\sum\limits_x \hat{P}(x) \log\hat{P}(x) - \sum\limits_x \hat{P}(x) \log P_\theta(x)$. Because $\sum\limits_x \hat{P}(x) \log\hat{P}(x)$ is a constant given a training dataset, we only need to minimize $- \sum\limits_x \hat{P}(x) \log P_\theta(x)$. This is equivalent to $\arg \max\limits_\theta \sum\limits_{i=1}^m \log P_\theta(x^{(i)})$, because $\arg \max\limits_\theta \sum\limits_{i=1}^m \log P_\theta(x^{(i)}) = \arg \max\limits_\theta \sum\limits_x \hat{P}(x) \log P_\theta(x)$.
\end{answer}
